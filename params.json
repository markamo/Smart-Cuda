{"name":"Smart CUDA version 0.0.1 (draft)","tagline":"Convenient CUDA wrappers for productive GPU programming","body":"![Smart CUDA](logo.png)\r\n# Welcome to Smart CUDA Library Project Page\r\n\r\n***\r\n\r\nSmart CUDA library is a lightweight C/C++ wrapper of the CUDA runtime API for productive natural-like CUDA programming. Smart CUDA follows the natural CUDA programming style; however, it provides low level abstraction to allow for a more convenient programming. In this way, Smart CUDA enhances developer productivity while attaining very high performance. Smart CUDA integrates seamlessly with C/C++ arrays and pointers, STL vector, and Thrust arrays. Smart CUDA only wraps the data on the device and host, therefore data on the host and device can have several wrappers and different views. This makes it very flexible, and allows easy integration with other platform and libraries.\r\n\r\n# Why Smart CUDA library? \r\nEven though I am relatively new to C/C++ and CUDA programming, I realized that a lightweight wrapper could boost gpu programming productivity. Thus, I developed several wrappers that preserved the natural programming style as I went through the CUDA Programming Guide. Smart CUDA is the compilation of the basic wrappers I have currently developed. Smart CUDA library is meant to complement the efforts of other libraries such as Thrust and Magma and help boost gpu programming productivity.\r\n\r\n***\r\n\r\n# FEATURES\r\n\r\n## Header-only library\r\n```C++\r\n#include \"smartCuda\\smartCuda_001d.h\" ////include smart cuda version 0.0.1 draft\r\n\r\n```\r\n## Minimal Learning\r\n```C++\r\n//// memory and data allocation \r\n//// smartArray has overloads for allocating up to 4D data\r\ntemplate <typename T, int mem_loc> \r\n\tinline T* smartArray( int sizeX, cudaError_t &cudaStatus);\r\n\r\n//// smartArray wrapper wraps arrays on cpu and gpu memories for convenient access and management\r\ntemplate <typename T, int mem_loc> \r\n\tclass smartArrayWrapper{};\r\n```\r\n***\r\n# Smart Array\r\n## Easy Memory Allocation\r\n```C++\r\ncudaError_t cudaStatus = cudaSuccess;\r\nconst int arraySize = 100000;\r\nint* h_a = smartArray<int,smartHost>(arraySize, cudaStatus); ////pageable host memory\r\nint* hp_a = smartArray<int,smartPinnedHost>(arraySize, cudaStatus); ////pinned host memory\r\nint* d_a = smartArray<int,smartDevice>(arraySize, cudaStatus); ////device memory \r\n```\r\n\r\n## Multidimensional array allocation (up to 4D)\r\n```C++\r\nconst int lenX = 10;\r\nconst int lenY = 20;\r\nconst int lenZ = 5;\r\nconst int lenW = 3;\r\n\r\n////allocation on CPU\r\nint* h_1D = smartArray<int,smartHost>(lenX, cudaStatus);\r\nint* h_2D = smartArray<int,smartHost>(lenX, lenY, cudaStatus);\r\nint* h_3D = smartArray<int,smartHost>(lenX, lenY, lenZ, cudaStatus);\r\nint* h_4D = smartArray<int,smartHost>(lenX, lenY, lenZ, lenW, cudaStatus);\r\n\r\n////allocation on GPU\r\nint* d_1D = smartArray<int,smartDevice>(lenX, cudaStatus);\r\nint* d_2D = smartArray<int,smartDevice>(lenX, lenY, cudaStatus);\r\nint* d_3D = smartArray<int,smartDevice>(lenX, lenY, lenZ, cudaStatus);\r\nint* d_4D = smartArray<int,smartDevice>(lenX, lenY, lenZ, lenW, cudaStatus);\r\n```\r\n***\r\n\r\n# Smart Array Wrapper\r\n## Convenient wrapper for data management\r\n```C++\r\n...\r\n////wrap array on host\r\nsmartArrayWrapper<int,smartHost> wHa(h_a,arraySize,scopeLocal);  \r\nsmartArrayWrapper<int,smartHost> wHb(h_b,arraySize,scopeLocal);\r\nsmartArrayWrapper<int,smartHost> wHc(h_c,arraySize,scopeLocal);\r\n\r\n////wrap array on device\r\nsmartArrayWrapper<int,smartDevice> wDa(d_a,arraySize,scopeLocal);\r\nsmartArrayWrapper<int,smartDevice> wDb(d_b,arraySize,scopeLocal);\r\nsmartArrayWrapper<int,smartDevice> wDc(d_c,arraySize,scopeLocal);\r\n\r\n\r\n////access the underlying array using the object.inner_ptr()\r\n\r\n......\r\n__global__ void addKernel(int *c, const int *a, const int *b)\r\n{\r\n\tint i = threadIdx.x + blockIdx.x * blockDim.x;\r\n    c[i] = a[i] + b[i];\r\n\ti += blockDim.x * gridDim.x;\r\n}\r\n\r\n....\r\n////access the underlying array using the object.inner_ptr()\r\naddKernel<<<16, 16>>>(wDc.inner_ptr(), wDa.inner_ptr(), wDb.inner_ptr());\r\n\r\n```\r\n\r\n\r\n## Convenient data transfers between CPU and GPU\r\n```C++\r\n...\r\n////wrap array on host\r\nsmartArrayWrapper<int,smartHost> wHa(h_a,arraySize,scopeLocal);  \r\nsmartArrayWrapper<int,smartHost> wHb(h_b,arraySize,scopeLocal);\r\nsmartArrayWrapper<int,smartHost> wHc(h_c,arraySize,scopeLocal);\r\n\r\n////wrap array on device\r\nsmartArrayWrapper<int,smartDevice> wDa(d_a,arraySize,scopeLocal);\r\nsmartArrayWrapper<int,smartDevice> wDb(d_b,arraySize,scopeLocal);\r\nsmartArrayWrapper<int,smartDevice> wDc(d_c,arraySize,scopeLocal);\r\n\r\n////transfer data from host to device \r\nwDa = wHa; ////quick data transfer\r\n\r\n////copy method has extended support and overloads for other data types\r\nwDb.copy(wHb); \r\n\r\n////do some work on the GPU\r\n\r\n\r\n////transfer data back to CPU\r\nwHc = wDc; \r\n\r\n```\r\n\r\n## Local and Global scopes for automatic memory deallocation\r\n```C++\r\n...\r\nconst int arraySize = 1000;\r\nint* h_1 = smartArray<int,smartHost>(arraySize,cudaStatus);\r\nint* h_2 = smartArray<int,smartHost>(arraySize,cudaStatus);\r\n{\r\n    ////wrap host and device data\r\n    ////use scopeLocal for managing data that is for local scopes\r\n    ////memory is automatically freed when the wrapper goes out of scope    \r\n    smartArrayWrapper<int,smartHost> wLocal(h_1,arraySize,scopeLocal); \r\n\r\n    ...\r\n    ////use scopeGlobal for managing data that is for global scopes\r\n    smartArrayWrapper<int,smartHost> wGlobal(h_2,arraySize,scopeGlobal);\r\n    ....\r\n    /////do some work\r\n    ....\r\n}//// data for h_1 automatically deleted because it is local scope. \r\n//// data for h_2 is preserved because it is global to the scope created. \r\n\r\n//// h_1 must be reinitialized before used again\r\nh_1 = smartArray<int,smartHost>(arraySize,cudaStatus);\r\n\r\nsmartArrayWrapper<int,smartHost> w2(h_1,arraySize,scopeGlobal); \r\n////do some work\r\n...\r\n////manual deletion of allocated memory\r\nw2.destroy();\r\n\r\n```\r\n\r\n## Indexing and Data Access (up to 4D) \r\n```C++\r\n...\r\nconst int lenX = 100;\r\nconst int lenY = 100;\r\n\r\nsmartArrayWrapper<int,smartDevice> wA(d_a,lenX, lenY,scopeLocal);\r\nsmartArrayWrapper<int,smartDevice> wB(d_b,lenX, lenY,scopeLocal);\r\nsmartArrayWrapper<int,smartDevice> wC(d_c,lenX, lenY,scopeLocal);\r\n\r\nint i = threadIdx.x + blockIdx.x * blockDim.x;\r\nint j = threadIdx.y + blockIdx.y * blockDim.y;\r\n\r\n////the following gives the same results\r\n//// traditional CUDA style\r\n////d_c[i + j * lenX] = d_a[i + j * lenX] * d_b[i + j * lenX]; \r\n//// traditional CUDA style possible with smart array wrapper\r\n////wC[i + j * lenX] = wA[i + j * lenX] * wB[i + j * lenX]; \r\n////wC(i + j * lenX) = wA(i + j * lenX) * wB(i + j * lenX); \r\n////convenient indexing\r\nwC(i,j) = wA(i,j) * wB(i,j); \r\n\r\n////supports upto 4 dimensions \r\nsmartArrayWrapper<int,smartDevice> w4(d_a,lenX, lenY, lenZ, lenW, scopeLocal);\r\nint results = w4(5,5,5,5);\r\n\r\n////access the nth data element \r\nint results = w4[117];\r\n\r\n```\r\n\r\n\r\n## Customized Views of Pre-Allocated Data(up to 4D) \r\n```C++\r\n...\r\nconst int arraySize = 1000;\r\nint* h_1 = smartArray<int,smartHost>(arraySize,cudaStatus);\r\n...\r\n////wrap array on host\r\nsmartArrayWrapper<int,smartHost> wView2D(h_1,arraySize,scopeLocal);  \r\nwView2D.setViewDim(100,10); //// view 1D array as a 2D 100 * 10 array\r\nint temp = wView2D.ViewAt(50,5); //// get data at 50,10 of the view (up to 4D view)\r\nint temp2 = wView2D.ViewAt_2D(45,2); //// alternative view method (only 2D view)\r\n\r\nsmartArrayWrapper<int,smartHost> wView3D(h_1,arraySize,scopeLocal);\r\nwView3D.setViewDim(10,10,10); //// view 1D array as a 3D 10 * 10 * 10 array\r\nint temp3 = wView3D.ViewAt(5,5,5); //// get data at 5,5,5 of the view (up to 4D view)\r\nint temp4 = wView3D.ViewAt_3D(4,5,2); //// alternative view method (only 3D view)\r\n\r\n////access the original array \r\n//// the setViewDim and viewAt methods do not modify the layout of the array\r\nint temp5 = wWiew3D[150]; ////access the original h_1 array at index 150 using []\r\nint temp6 = wWiew2D(300); ////access the original h_1 array at index 300 using ()\r\n...\r\n```\r\n\r\n## Navigation (up to 4D indexing) \r\n** Navigation using PEEK, SEEK, and ADV(advance)**\r\n```C++\r\n...\r\nconst int arraySize = 1000;\r\nint* d_1 = smartArray<int,smartDevice>(arraySize,cudaStatus);\r\n...\r\n////wrap array on device\r\nsmartArrayWrapper<int,smartDevice> wNav(d_1,arraySize,scopeLocal);  \r\n...\r\n////navigate through the data \r\n////peek examples\r\nint peek1 = wNav.peek(); ////get the next data without moving the data access position\r\nint peek5 = wNav.peek(5); ////get the next 5th position data without moving the data access position\r\nint peek_3 = wNav.peek(-3); ////get the previous 3rd position data without moving the data access position\r\n...\r\n////adv examples\r\nint adv1= wNav.seek(); ////move to the next data and return a reference to the data\r\nint adv5 = wNav.seek(5); ////move to the next 5th position data and return a reference\r\nint adv_3 = wNav.seek(-3); ////move to the previous 3rd position data and return a reference\r\n\r\n...\r\n////seek examples\r\nint seek1 = wNav.seek(); ////move to the next data and return a reference to the data\r\nint seek5 = wNav.seek(5); ////move to the 5th position data and return a reference\r\nint seek_3 = wNav.seek(3); ////move to the 3rd position data and return a reference ////negative index not allow\r\n\r\n....\r\n/////other peek, seek and adv methods\r\n////peek4(),seek4(),adv4() uses convenient indexing to navigate the data as above\r\nint seek4 = wNav.seek4(2,5,1,3); ////move to the 2,5,1,3 position data and return a reference\r\nint adv4 = wNav.seek(-3,1,2); ////move to -3,1,2 position from the current index data and return a reference\r\nint peek4 = wNav.peek4(5,7); ////get the data at index 5,7 from the current position without moving the data access position\r\n...\r\n/////other navigation methods\r\nint nav_ref = wNav++; ////returns a reference to the next data element and increases the data access index\r\nint nav = ++wNav; ////returns the value of the next data element and increases the data access index\r\n\r\nint nav_ref1 = wNav--; ////returns a reference to the previous data element and decreases the data access index\r\nint nav1 = --wNav; ////returns the value of the previous data element and decreases the data access index\r\n\r\n\r\n```\r\n\r\n***\r\n\r\n# Latest News\r\n*SmartCUDA v 0.0.1(draft-release) - 16th December, 2013\r\n\r\n### Features under consideration for future releases\r\n- [ ] Smart Kernel\r\n- [ ] Smart Device\r\n- [ ] SmartArrayWrapper.apply_func()\r\n- [ ] SmartArrayWrapper.apply_funcAsync()\r\n- [ ] SmartArrayWrapper.sort()\r\n- [ ] SmartArrayWrapper.sortAsync()\r\n- [ ] SmartArrayWrapper.reduce()\r\n- [ ] SmartArrayWrapper.scan()\r\n- [ ] Smart Array Wrapper basic mathematical operators\r\n- [ ] Basic integration with STL::array and STL::vector\r\n- [ ] Basic integration with Thrust::host_vector and Thrust::device_vector\r\n- [ ] Basic integration with OpenCL, OpenMP, TBB, and C++ AMP \r\n- [ ] Integration with other CUDA libraries \r\n- [ ] Multi-Host and Multi-Device data allocation and management\r\n- [ ] Etc.\r\n\r\n### Authors and Contributors\r\nThe original creator of Smart CUDA is Mark Amo-Boateng (@markamo). \r\n\r\n### Support or Contact\r\nHaving trouble with Smart CUDA? Check out the documentation at https://github.com/markamo/Smart-Cuda or contact smartcuda@outlook.com and we’ll help you sort it out.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}